# My first Datalabs Spark cluster

In this tutorial, you will create a *Spark cluster* within Datalabs and use it inside a notebook.

A Spark cluster created this way must use the same Conda environment as your notebook, and
requires a project storage.

It is recommended that you should already be familiar with the material in the tutorial
[My first Jupyter project](../getting-started-jupyter/).

1. [What is a Spark cluster?](01-what-is-a-spark-cluster.md)
1. [Getting ready](02-getting-ready.md)
1. [Create a Spark cluster](03-create-spark-cluster.md)
1. [Start Spark session](04-start-spark-session.md)
1. [Perform Spark calculation (Python)](05-perform-spark-calculation-python.md)
1. [Perform Spark calculation (R)](06-perform-spark-calculation-r.md)
1. [Delete Spark cluster](07-delete-spark-cluster.md)
1. [Conclusion](08-conclusion.md)
