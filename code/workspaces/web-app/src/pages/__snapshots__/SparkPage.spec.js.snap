// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`SparkPage renders correct snapshot 1`] = `
<WithStyles(Page)
  className=""
  title="Spark"
>
  <WithStyles(ForwardRef(Typography))
    variant="body1"
  >
    <ExternalLink
      href="https://spark.apache.org/"
    >
      Apache Spark
    </ExternalLink>
     is an open-source cluster-computing framework.
    <br />
    DataLabs supports usage of Spark via Kubernetes which allows Spark executors to be deployed across the cluster.
  </WithStyles(ForwardRef(Typography))>
  <div
    className="makeStyles-clusterList-1"
  >
    <ClustersContainer
      clusterType="SPARK"
      copySnippet={[Function]}
    />
  </div>
</WithStyles(Page)>
`;

exports[`getMessage returns the correct message 1`] = `
"import os
import pyspark

conf = pyspark.SparkConf()
# The below option can be altered depending on your memory requirement.
# The maximum value is the amount of memory assigned to each worker, minus 1GB.
conf.set('spark.executor.memory', '3g')

os.environ[\\"PYSPARK_PYTHON\\"] = \\"/data/conda/myenv/bin/python\\"
os.environ[\\"PYSPARK_DRIVER_PYTHON\\"] = \\"/data/conda/myenv/bin/python\\"

sc = pyspark.SparkContext(master=\\"spark://spark-scheduler-mycluster:7077\\", conf=conf)
sc
"
`;
