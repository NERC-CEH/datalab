// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`deploymentGenerator createDatalabDaskSchedulerDeployment uses dask image if no volumeMount/condaPath set 1`] = `
"apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-name
spec:
  replicas: 1
  selector:
    matchLabels:
      dask-infra: scheduler-pod-label
  template:
    metadata:
      labels:
        dask-infra: scheduler-pod-label
    spec:
      containers:
        - image: dask-image
          command: [\\"bash\\"]
          args: [\\"-c\\", \\"dask-scheduler\\"]
          name: dask-scheduler-cont
          ports:
            - containerPort: 8786
            - containerPort: 8787
          resources:
            requests:
              memory: scheduler-memory
              cpu: scheduler-cpu
            limits:
              memory: scheduler-memory
              cpu: scheduler-cpu
          volumeMounts:
      hostname: dask-scheduler-host
      restartPolicy: Always
      volumes:
"
`;

exports[`deploymentGenerator createDatalabDaskSchedulerDeployment uses jupyter image if volumeMount/condaPath set 1`] = `
"apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-name
spec:
  replicas: 1
  selector:
    matchLabels:
      dask-infra: scheduler-pod-label
  template:
    metadata:
      labels:
        dask-infra: scheduler-pod-label
    spec:
      containers:
        - image: lab-image
          command: [\\"bash\\"]
          args: [\\"-c\\", \\"/data/conda/some-env/bin/dask-scheduler\\"]
          name: dask-scheduler-cont
          ports:
            - containerPort: 8786
            - containerPort: 8787
          resources:
            requests:
              memory: scheduler-memory
              cpu: scheduler-cpu
            limits:
              memory: scheduler-memory
              cpu: scheduler-cpu
          volumeMounts:
            - name: persistentfsvol
              mountPath: /data
      hostname: dask-scheduler-host
      restartPolicy: Always
      volumes:
        - name: persistentfsvol
          persistentVolumeClaim:
            claimName: volume-mount-claim
"
`;

exports[`deploymentGenerator createDatalabDaskWorkerDeployment uses dask image if no volumeMount/condaPath set 1`] = `
"apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-name
spec:
  replicas: 1
  selector:
    matchLabels:
      dask-infra: worker-pod-label
  template:
    metadata:
      labels:
        dask-infra: worker-pod-label
    spec:
      containers:
        - image: dask-image
          command: [\\"bash\\"]
          args: [\\"-c\\", \\"dask-worker --nthreads n-threads --no-dashboard --memory-limit worker-memory --death-timeout death-timeout-sec tcp://scheduler-service-name:8786\\"]
          name: dask-worker-cont
          resources:
            requests:
              memory: worker-memory
              cpu: worker-cpu
            limits:
              memory: worker-memory
              cpu: worker-cpu
          volumeMounts:
      hostname: dask-worker-host
      restartPolicy: Always
      volumes:
"
`;

exports[`deploymentGenerator createDatalabDaskWorkerDeployment uses jupyter image if volumeMount/condaPath set 1`] = `
"apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-name
spec:
  replicas: 1
  selector:
    matchLabels:
      dask-infra: worker-pod-label
  template:
    metadata:
      labels:
        dask-infra: worker-pod-label
    spec:
      containers:
        - image: lab-image
          command: [\\"bash\\"]
          args: [\\"-c\\", \\"/data/conda/some-env/bin/dask-worker --nthreads n-threads --no-dashboard --memory-limit worker-memory --death-timeout death-timeout-sec tcp://scheduler-service-name:8786\\"]
          name: dask-worker-cont
          resources:
            requests:
              memory: worker-memory
              cpu: worker-cpu
            limits:
              memory: worker-memory
              cpu: worker-cpu
          volumeMounts:
            - name: persistentfsvol
              mountPath: /data
      hostname: dask-worker-host
      restartPolicy: Always
      volumes:
        - name: persistentfsvol
          persistentVolumeClaim:
            claimName: volume-mount-claim
"
`;

exports[`deploymentGenerator createRStudioConfigMap produces expected configmap 1`] = `
"---
apiVersion: v1
kind: ConfigMap
metadata:
  name: configmap-name
data:
  X-RStudio-Root-Path /base/path
"
`;

exports[`deploymentGenerator createRStudioDeployment creates expected manifest 1`] = `
"---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    name: rstudio-name
  name: rstudio-name
spec:
  selector:
    matchLabels:
      name: rstudio-name
  template:
    metadata:
      labels:
        name: rstudio-name
        user-pod: rstudio
    spec:
      initContainers:
        # This container will generate the RStudio notebooks directory. RStudio starts with /home/datalabs as its initial
        # start-up/default directory and has not environmental variable to change it. This is fixed by mounting an empty
        # directory as /home and created a symlink datalabs pointing to /data/notebooks/rstudio
        - name: create-notebook-folders
          image: busybox
          imagePullPolicy: IfNotPresent
          command: [\\"sh\\"]
          args: [\\"-c\\", \\"mkdir -p /data/notebooks/rstudio-name\\"]
          volumeMounts:
            - mountPath: /data
              name: persistentfsvol
        # This container sets the folder permissions for the generated notebook directory to be usable by
        # datalabs:users.
        - name: set-directory-permissions
          image: busybox
          imagePullPolicy: IfNotPresent
          command: [\\"sh\\"]
          args: [\\"-c\\", \\"chmod 777 /data/notebooks && chmod 777 /data/notebooks/rstudio-name\\"]
          volumeMounts:
            - mountPath: /data
              name: persistentfsvol
        # This container will create the /home/datalabs to /data/notebooks/rstudio symlink
        - name: create-datalab-symlink
          image: busybox
          imagePullPolicy: IfNotPresent
          command: [\\"sh\\", \\"-c\\", \\"ln -s /data/notebooks/rstudio-name/ /home/datalab\\"]
          volumeMounts:
            - mountPath: /home
              name: homedir
      containers:
        - name: rstudio-name-connect
          image: nerc/zeppelin-connect:1.2.0
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8000
              protocol: TCP
          env:
            - name: CONNECT_TYPE
              value: RSTUDIO
          livenessProbe:
            httpGet:
              path: /status
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
        - name: rstudio-name
          image: nerc/rstudio:4.0.1
          imagePullPolicy : IfNotPresent
          ports:
            - containerPort: 8787
              protocol: TCP
          env:
            - name: USER
              value: datalab
            - name: PASSWORD
              valueFrom:
                secretKeyRef:
                  name: rstudio-name
                  key: password
            - name: ROOT
              value: 'TRUE'
          resources:
            requests:
              cpu: 200m
              memory: 128Mi
            limits:
              cpu: 2
              memory: 8Gi
          livenessProbe:
            httpGet:
              path: /
              port: 8787
            initialDelaySeconds: 5
            periodSeconds: 10
          volumeMounts:
            - name: persistentfsvol
              mountPath: /data
            - name: homedir
              mountPath: /home
      volumes:
        - name: persistentfsvol
          persistentVolumeClaim:
            claimName: volumeMount-claim
        - name: homedir
          emptyDir: {}
"
`;

exports[`deploymentGenerator generates createAutoScaler manifest 1`] = `
"apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: auto-scaler-name
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: scale-deployment-name
  minReplicas: 1
  maxReplicas: max-replicas
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: target-cpu-utilization
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: target-memory-utilization
  behavior:
    scaleDown:
      stabilizationWindowSeconds: scale-down-window-sec
"
`;

exports[`deploymentGenerator generates createDatalabDaskSchedulerNetworkPolicy manifest 1`] = `
"apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: policy-name
spec:
  podSelector:
    matchLabels:
      dask-infra: scheduler-pod-label
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: project-key
    ports:
    - protocol: TCP
      port: 8786
    - protocol: TCP
      port: 8787
"
`;

exports[`deploymentGenerator generates createDatalabDaskSchedulerService manifest 1`] = `
"apiVersion: v1
kind: Service
metadata:
  name: service-name
spec:
  ports:
    - name: \\"client\\"
      port: 8786
      targetPort: 8786
    - name: \\"dashboard\\"
      port: 8787
      targetPort: 8787
  selector:
    dask-infra: scheduler-pod-label
"
`;

exports[`deploymentGenerator generates createJupyterDeployment manifest 1`] = `
"---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    name: deployment-name
  name: deployment-name
spec:
  selector:
    matchLabels:
      name: deployment-name
  template:
    metadata:
      labels:
        name: deployment-name
        user-pod: jupyterlab
    spec:
      securityContext:
        runAsUser: 0
      serviceAccountName: project-key-compute-submission-account
      initContainers:
        # This container will generate the expected folder structure for the notebooks directory, without this the
        # jupyter container will not start. As the container runs a root these directories are owned by root and can
        # not be written to by datalabs:users (user:group; 1000:100).
        - name: create-notebook-folders
          image: busybox
          imagePullPolicy: IfNotPresent
          command: [\\"sh\\"]
          args: [\\"-c\\", \\"mkdir -p /mnt/persistentfs/notebooks/deployment-name\\"]
          volumeMounts:
            - mountPath: /mnt/persistentfs
              name: persistentfsvol
        # This container sets the folder permissions for the generated notebook directory to be usable by
        # datalabs:users.
        - name: set-directory-permissions
          image: busybox
          imagePullPolicy: IfNotPresent
          command: [\\"sh\\"]
          args: [\\"-c\\", \\"chmod 777 /mnt/persistentfs/notebooks && chmod 777 /mnt/persistentfs/notebooks/deployment-name\\"]
          volumeMounts:
            - mountPath: /mnt/persistentfs
              name: persistentfsvol
      containers:
        - image: nerc/jupyterlab:fbf2130-dask-2.30
          imagePullPolicy : \\"IfNotPresent\\"
          name: deployment-name
          command: [\\"start.sh\\",
            \\"jupyter\\", \\"lab\\",
            \\"--NotebookApp.token=$(JUPYTER_TOKEN)\\",
            \\"--NotebookApp.allow_origin=project-key-notebook-name.datalabs.localhost\\",
            \\"--NotebookApp.notebook_dir=/data/notebooks/deployment-name\\",
            \\"--NotebookApp.base_url=/resource/project-key/notebook-name\\"]
          ports:
            - containerPort: 8888
              protocol: TCP
          env:
            - name: JUPYTER_TOKEN
              valueFrom:
                secretKeyRef:
                  name: deployment-name
                  key: token
            - name: GRANT_SUDO
              value: \\"yes\\"
            - name: R_LIBS_USER
              value: \\"/data/packages/R/%p/%v\\"
            - name: JUPYTER_DATA_DIR
              value: \\"/data/.jupyter\\"
            - name: CONDA_ENV_DIR
              value: \\"/data/conda/\\"
            - name: JUPYTER_ALLOW_INSECURE_WRITES
              value: 'true'
          resources:
            requests:
              cpu: 200m
              memory: 128Mi
            limits:
              cpu: 2
              memory: 8Gi
          livenessProbe:
            httpGet:
              path: /resource/project-key/notebook-name
              port: 8888
            initialDelaySeconds: 5
            periodSeconds: 10
          volumeMounts:
            - name: persistentfsvol
              mountPath: /data
            - name: spark-kubernetes-properties
              # /usr/local/spark is default value of $SPARK_HOME set in the
              # base jupyter/pyspark-notebook Dockerfile
              mountPath: /usr/local/spark/conf/spark-defaults.conf
              subPath: spark-defaults.conf
            - name: dask-kubernetes-properties
              mountPath: /opt/conda/etc/dask/dask.yaml
              subPath: dask.yaml
            - name: jupyter-notebook-config
              mountPath: /home/datalab/.jupyter/jupyter_notebook_config.py
              subPath: jupyter-notebook-config.py
      volumes:
        - name: persistentfsvol
          persistentVolumeClaim:
            claimName: volume-mount-claim
        - name: spark-kubernetes-properties
          configMap:
            name: deployment-name-pyspark-config
            items:
              - key: config
                path: spark-defaults.conf
        - name: dask-kubernetes-properties
          configMap:
            name: deployment-name-dask-config
            items:
            - key: config
              path: dask.yaml
        - name: jupyter-notebook-config
          configMap:
            name: deployment-name-jupyter-config
            items:
            - key: config
              path: jupyter-notebook-config.py
"
`;
