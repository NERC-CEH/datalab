{"paragraphs":[{"title":"Create Case Classes for Data Import","text":"import org.apache.spark.sql.{Row, SparkSession}\nimport org.apache.spark.sql.types.{DoubleType, IntegerType, StructField, StructType}\nimport org.apache.spark.sql.functions._\n\ncase class ResultRow(lcmClass: Int, year: Int, predictedRichness: Double)\ncase class OutputFeature(geometry: String, modalClass: Int, richness: Array[(Double, Double)])","user":"anonymous","dateUpdated":"2017-06-21T16:14:33+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498061642594_172667070","id":"20170620-143527_1759559639","dateCreated":"2017-06-21T16:14:02+0000","dateStarted":"2017-06-21T16:14:33+0000","dateFinished":"2017-06-21T16:14:49+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:50460"},{"title":"Create functions for data processing","text":"def parseFeature(row: Row) : OutputFeature = {\n    val geometryString = row.getAs[String](\"_c0\")\n    val modalClass = row.getAs[String](\"_c7\").toInt\n    \n    OutputFeature(geometryString, modalClass, null)\n}\n\ndef getRowForYearAndModalClass(year: Int, modalClass: Int,\n                             lookup: Array[((Int, Int), Double, Double)]): Option[((Int, Int), Double, Double)] = {\n    lookup.find(row => row._1._1 == year && row._1._2 == modalClass)\n}\n\ndef getPredictedValueForYearAndModalClass(year: Int, modalClass: Int,\n                                        lookup: Array[((Int, Int), Double, Double)]) : Double = {\n    val row = getRowForYearAndModalClass(year, modalClass, lookup)\n    if (row.isDefined) {\n      row.get._2\n    } else {\n      0\n    }\n}\n\ndef getVarianceForYearAndModalClass(year: Int, modalClass: Int,\n                                        lookup: Array[((Int, Int), Double, Double)]) : Double = {\n    val row = getRowForYearAndModalClass(year, modalClass, lookup)\n    if (row.isDefined) {\n      row.get._3\n    } else {\n      0\n    }\n}","user":"anonymous","dateUpdated":"2017-06-21T16:14:53+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498061642596_170358577","id":"20170620-143555_28800291","dateCreated":"2017-06-21T16:14:02+0000","dateStarted":"2017-06-21T16:14:53+0000","dateFinished":"2017-06-21T16:14:54+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:50461"},{"title":"Create Aggregated Lookup Table","text":"import spark.implicits._\n\nval resultsFilePath = \"/data/LandCoverModel/spark_io/massPqlResult/part*\"\n\nval schema = StructType(Array(\n  StructField(\"lcmClass\", IntegerType),\n  StructField(\"year\", IntegerType),\n  StructField(\"predictedRichness\", DoubleType)))\n\nval resultDataset = spark.sqlContext.read.format(\"csv\").schema(schema).csv(resultsFilePath).as[ResultRow]\nval resultLookup = resultDataset\n  .groupByKey(x => (x.year, x.lcmClass))\n  .agg(avg(\"predictedRichness\").as[Double], variance(\"predictedRichness\").as[Double])\n  .cache()\n\nval lookup = resultLookup.collect()","user":"anonymous","dateUpdated":"2017-06-22T13:26:57+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498061642597_169973828","id":"20170620-143713_707572954","dateCreated":"2017-06-21T16:14:02+0000","dateStarted":"2017-06-21T16:16:06+0000","dateFinished":"2017-06-21T16:16:13+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:50462"},{"title":"Augment Land Cover Map with Predicted values","text":"// Broadcast lookup table to nodes\nval bLookup = spark.sparkContext.broadcast(lookup)\n\n\nval lcmFilePath = \"/data/LandCoverModel/spark_io/inputData/25m_subset_csv/smallWKT.aa\"\n// val lcmFilePath = \"/data/LandCoverModel/spark_io/inputData/25mcsv/lcm25mWKT.*\"\nval lcmReader = spark.read.csv(lcmFilePath)\nval lcmData = lcmReader.rdd.map(row => parseFeature(row))\n\nval predictedMap = lcmData.map(feature => {\n  val years = Array(1978, 1990, 1998, 2007)\n\n  val richness = years.map(year => {\n    val predictedRichness = getPredictedValueForYearAndModalClass(year, feature.modalClass, bLookup.value)\n    val variance = getVarianceForYearAndModalClass(year, feature.modalClass, bLookup.value)\n\n    (predictedRichness, variance)\n  })\n\n  OutputFeature(feature.geometry, feature.modalClass, richness)\n})","user":"anonymous","dateUpdated":"2017-06-22T13:26:57+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498061642598_171128075","id":"20170620-143808_860005175","dateCreated":"2017-06-21T16:14:02+0000","dateStarted":"2017-06-21T16:20:01+0000","dateFinished":"2017-06-21T16:20:02+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:50463"},{"title":"Write data to file","text":"val outputPath = \"/data/LandCoverModel/spark_io/resultRichness\" + System.currentTimeMillis\npredictedMap.map(row => {\n  val geometryString = \"\\\"\" + row.geometry + \"\\\"\"\n  val richnessValues = row.richness.flatMap(r => List(r._1, r._2)).mkString(\",\")\n  val outputVals = Array(geometryString, row.modalClass, richnessValues)\n  outputVals.mkString(\",\")\n}).saveAsTextFile(outputPath)","user":"anonymous","dateUpdated":"2017-06-22T13:26:57+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498061642599_170743326","id":"20170620-143850_210570896","dateCreated":"2017-06-21T16:14:02+0000","dateStarted":"2017-06-21T16:20:05+0000","dateFinished":"2017-06-21T16:20:07+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:50464"},{"dateUpdated":"2017-06-21T16:14:02+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498061642600_168819581","id":"20170620-144139_1516321013","dateCreated":"2017-06-21T16:14:02+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:50465"}],"name":"Create Output Map Data","id":"2CMUZD35M","angularObjects":{"2CJCG9YGH:shared_process":[],"2CMMNW7MR:shared_process":[],"2CKEQTZDW:shared_process":[],"2CNKKUJDJ:shared_process":[],"2CK113UY1:shared_process":[],"2CMCUVPQV:shared_process":[],"2CKUQT3KT:shared_process":[],"2CMT2DHBM:shared_process":[],"2CN4BZX5B:shared_process":[],"2CKBH6PKV:shared_process":[],"2CNH6WYSG:shared_process":[],"2CJZHZPXJ:shared_process":[],"2CMUXRQW7:shared_process":[],"2CJDPRR2G:shared_process":[],"2CK3RHEJU:shared_process":[],"2CK68AC9T:shared_process":[],"2CNQJ1MP7:shared_process":[],"2CKEKKSZA:shared_process":[],"2CKV2TXGB:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}