{"paragraphs":[{"title":"Import CSV using Scala","text":"val filePath = \"/data/LandCoverModel/spark_io/LCM_25m_combined/part*\"\nval lcmDataSet = sqlContext.read.format(\"csv\").option(\"inferSchema\", \"true\").load(filePath)\n\nval requiredColumns = lcmDataSet.select(\"_c0\", \"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\", \"_c6\")\nval columnNames = Seq(\"TOTRICH78\", \"TOTRICH90\", \"TOTRICH98\", \"TOTRICH07\", \"PIX_DIST\", \"MODAL_CLASS\", \"REPEAT_PLO\")\nval lcmCleanData = requiredColumns.toDF(columnNames: _*).dropDuplicates(\"REPEAT_PLO\")\n\nrequiredColumns.count()\nlcmCleanData.count() // count after dropping duplicates\n\nlcmCleanData.createOrReplaceTempView(\"cleandata\")\nlcmCleanData.show(5)","user":"anonymous","dateUpdated":"2017-06-22T14:30:18+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nfilePath: String = /data/LandCoverModel/spark_io/LCM_25m_combined/part*\n\nlcmDataSet: org.apache.spark.sql.DataFrame = [_c0: int, _c1: int ... 5 more fields]\n\nrequiredColumns: org.apache.spark.sql.DataFrame = [_c0: int, _c1: int ... 5 more fields]\n\ncolumnNames: Seq[String] = List(TOTRICH78, TOTRICH90, TOTRICH98, TOTRICH07, PIX_DIST, MODAL_CLASS, REPEAT_PLO)\n\nlcmCleanData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [TOTRICH78: int, TOTRICH90: int ... 5 more fields]\n\nres2: Long = 17340\n\nres3: Long = 7054\n+---------+---------+---------+---------+--------------------+-----------+----------+\n|TOTRICH78|TOTRICH90|TOTRICH98|TOTRICH07|            PIX_DIST|MODAL_CLASS|REPEAT_PLO|\n+---------+---------+---------+---------+--------------------+-----------+----------+\n|        0|       29|       31|       32|0,0,0,0,0,0,1027,...|         10| 1025RPT17|\n|        0|       24|       21|       17|0,0,0,37,0,0,0,0,...|          4| 1058RPT26|\n|        0|        0|        0|        8|0,0,0,41,0,0,0,0,...|          4| 1125RPT22|\n|        0|        0|        0|       16|0,0,0,0,0,0,0,0,0...|         11| 1138RPT32|\n|        0|       20|        9|        8|0,0,0,17,0,0,61,0...|          7| 1202RPT20|\n+---------+---------+---------+---------+--------------------+-----------+----------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1498059494900_1504987402","id":"20170615-135058_169881588","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:30:18+0000","dateFinished":"2017-06-22T14:30:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1580"},{"title":"Collect data in a SparkR Data Frame using SQL","text":"%r\ndtf <- sql(\"select TOTRICH78, TOTRICH90, TOTRICH98, TOTRICH07, PIX_DIST, MODAL_CLASS,  REPEAT_PLO from cleandata\")\nstr(dtf)","user":"anonymous","dateUpdated":"2017-06-22T14:31:56+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n'SparkDataFrame': 7 variables:\n $ TOTRICH78  : int 0 0 0 0 0 14\n $ TOTRICH90  : int 29 24 0 0 20 22\n $ TOTRICH98  : int 31 21 0 0 9 21\n $ TOTRICH07  : int 32 17 8 16 8 19\n $ PIX_DIST   : chr “0,0,0,0,0,0,1027,0,160,1692,0,0,0,0,0,0,0,0,0,0,0” “0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0” “0,\n $ MODAL_CLASS: int 10 4 4 11 7 11\n $ REPEAT_PLO : chr \"1025RPT17” “1058RPT26” “1125RPT22” “1138RPT32” “1202RPT20” “1205RPT17”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494900_1504987402","id":"20170615-120921_1884821392","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:31:57+0000","dateFinished":"2017-06-22T14:31:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1581"},{"title":"Reshape data","text":"%r\ncolumnYearLabels <- list(c(\"TOTRICH78\", \"1978\"), c(\"TOTRICH90\", \"1990\"), c(\"TOTRICH98\", \"1998\"), c(\"TOTRICH07\", \"2007\"))\n\nreshapeTR <- function(columnYear) {\n    dtf.filt <- select(dtf, columnYear[1], \"PIX_DIST\", \"MODAL_CLASS\", \"REPEAT_PLO\")\n    dtf.filt$YR <- lit(columnYear[2])\n    dtf.tr <- withColumnRenamed(dtf.filt, columnYear[1], \"TOTRICH\")\n    dtf.tr\n}\n\ndtfAll <- do.call(rbind, lapply(columnYearLabels, reshapeTR))\n\nstr(dtfAll)","user":"anonymous","dateUpdated":"2017-06-22T14:32:02+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n'SparkDataFrame': 5 variables:\n $ TOTRICH    : int 0 0 0 0 0 14\n $ PIX_DIST   : chr “0,0,0,0,0,0,1027,0,160,1692,0,0,0,0,0,0,0,0,0,0,0” “0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0” “0,\n $ MODAL_CLASS: int 10 4 4 11 7 11\n $ REPEAT_PLO : chr \"1025RPT17” “1058RPT26” “1125RPT22” “1138RPT32” “1202RPT20” “1205RPT17”\n $ YR         : chr “1978” “1978” “1978” “1978” “1978” “1978”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494901_1504602653","id":"20170620-104153_1943863007","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:32:02+0000","dateFinished":"2017-06-22T14:32:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1582"},{"title":"Spark GLM Introduction","text":"%md\nWhen using R in Zeppelin the library `SparkR` is loaded in the background, this masks some underlying base R functions, most notable the `glm` function is now `SparkR::glm`. This function utilises the `MLlib` Spark library which is very fast for large datasets, but lacks functionality seen with base R glm function. Currently only a few formula operators are supported, including `~`, `.`, `:`, `+`, and `-`. Only `binomial`, `gaussian`, `Gamma`, and `poisson` families will work with `SparkR::glm`. Furthermore, R style factors can not be applied to Spark Data Frames, however, the same effect can be achieve by converting the column to strings.\n\nOur original formula for `stats::glm` was `(TOTRICH+1)~LCM*YR`, this has had to be modified to a two step process.Firstly, we mutate the `TOTRICH` column by adding 1 and convert `LCM` and `YR` to strings - as seen with the `toModel` variable. Secondly, the interaction `A*B` shorthand is not recognised and has to be expanded to be `A+B+A:B`.","user":"anonymous","dateUpdated":"2017-06-22T13:29:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>When using R in Zeppelin the library <code>SparkR</code> is loaded in the background, this masks some underlying base R functions, most notable the <code>glm</code> function is now <code>SparkR::glm</code>. This function utilises the <code>MLlib</code> Spark library which is very fast for large datasets, but lacks functionality seen with base R glm function. Currently only a few formula operators are supported, including <code>~</code>, <code>.</code>, <code>:</code>, <code>+</code>, and <code>-</code>. Only <code>binomial</code>, <code>gaussian</code>, <code>Gamma</code>, and <code>poisson</code> families will work with <code>SparkR::glm</code>. Furthermore, R style factors can not be applied to Spark Data Frames, however, the same effect can be achieve by converting the column to strings.</p>\n<p>Our original formula for <code>stats::glm</code> was <code>(TOTRICH+1)~LCM*YR</code>, this has had to be modified to a two step process.Firstly, we mutate the <code>TOTRICH</code> column by adding 1 and convert <code>LCM</code> and <code>YR</code> to strings - as seen with the <code>toModel</code> variable. Secondly, the interaction <code>A*B</code> shorthand is not recognised and has to be expanded to be <code>A+B+A:B</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1498059494901_1504602653","id":"20170616-152529_553294767","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T13:29:53+0000","dateFinished":"2017-06-22T13:29:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1583"},{"title":"Model \"Modal Class\" using SparkR GLM","text":"%r\n# SparkR GLM can not mutate values before modelling\ntoModel <- mutate(dtfAll, TOTRICH=cast(dtfAll$TOTRICH + 1, \"integer\"), MODAL_CLASS=cast(dtfAll$MODAL_CLASS, \"string\"))\nstr(toModel)\n\nsparkFit <- glm(TOTRICH~MODAL_CLASS+YR+MODAL_CLASS:YR, family=poisson, data=toModel)","user":"anonymous","dateUpdated":"2017-06-22T14:32:07+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n'SparkDataFrame': 5 variables:\n $ TOTRICH    : int 1 1 1 1 1 15\n $ PIX_DIST   : chr “0,0,0,0,0,0,1027,0,160,1692,0,0,0,0,0,0,0,0,0,0,0” “0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0” “0,\n $ MODAL_CLASS: chr \"10” “4” “4” “11” “7” “11”\n $ REPEAT_PLO : chr “1025RPT17” “1058RPT26” “1125RPT22” “1138RPT32” “1202RPT20” “1205RPT17”\n $ YR         : chr “1978” “1978” “1978” “1978” “1978” “1978”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494901_1504602653","id":"20170615-135849_1422525712","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:32:07+0000","dateFinished":"2017-06-22T14:32:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1584"},{"title":"Create prediction data-set from Spark Data Frame","text":"%r\n# Created SparkR Data Frame is unordered\ntoFitNewValues <- arrange(distinct(select(toModel, \"MODAL_CLASS\", \"YR\")), \"YR\", \"MODAL_CLASS\")\nstr(toFitNewValues)","user":"anonymous","dateUpdated":"2017-06-22T14:32:39+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n'SparkDataFrame': 2 variables:\n $ MODAL_CLASS: chr “1” “10” “11” “12” “13” “14”\n $ YR         : chr “1978” “1978” “1978” “1978” “1978” “1978”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170619-081700_893612832","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:32:39+0000","dateFinished":"2017-06-22T14:32:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1585"},{"title":"Generate predictions from Spark GLM model","text":"%r\n# Spark::Predict missing level and type arguments \nsparkPredict <- predict(sparkFit, newData = toFitNewValues)\nhead(sparkPredict)","user":"anonymous","dateUpdated":"2017-06-22T14:32:44+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nMODAL_CLASS   YR prediction\n1           1 1978   3.311475\n2          10 1978   4.605364\n3          11 1978   4.154799\n4          12 1978   2.200000\n5          13 1978   3.800000\n6          14 1978   4.097222\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170616-135554_478749562","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:32:44+0000","dateFinished":"2017-06-22T14:32:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1586"},{"title":"Define the pixel distribution sampler function","text":"%r\npixDistSampler <- function(sparkDF) {\n    # sparkDataFrame is a fragment of the entire data frame.\n    nrows <- nrow(sparkDF)\n    for(i in 1:nrows){\n        row <- sparkDF[i,]\n        pixDist.counts <- as.double(unlist(strsplit(row$PIX_DIST, \",\")))\n        pixDist.randCount <- sum(pixDist.counts) * row$RAND\n        pixDist.csum <- cumsum(pixDist.counts)\n        pixDist.idx <- which(pixDist.csum >= pixDist.randCount)\n        sparkDF[i,6] <-  as.integer(pixDist.idx[1])\n    }\n    sparkDF\n}\n\npixDistSampler.schema <- structType(structField(\"TOTRICH\", \"integer\"), structField(\"PIX_DIST\", \"string\"),  structField(\"YR\", \"string\"), structField(\"REPEAT_PLO\", \"string\"),\n     structField(\"RAND\", \"double\"), structField(\"MODAL_CLASS\", \"integer\"))","user":"anonymous","dateUpdated":"2017-06-22T14:32:49+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170619-164436_953728566","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:32:49+0000","dateFinished":"2017-06-22T14:32:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1587"},{"title":"Define Spark GLM Monte Carlo function","text":"%r\nsparkGlmMC <- function(runIdx) {\n    runSelect <- select(dtfAll, \"TOTRICH\", \"PIX_DIST\", \"YR\", \"REPEAT_PLO\")\n    runData <- dapply(withColumn(runSelect, \"RAND\", rand()), pixDistSampler, pixDistSampler.schema)\n    runMut <- mutate(runData, TOTRICH = runData$TOTRICH + 1L, MODAL_CLASS = cast(runData$MODAL_CLASS, \"string\"))\n    # Writing then reading the data from disk dramatically speeds up each loop. (6 loops; 10m24s [without write] -> 1m45s [with write])\n    write.df(runMut, path=\"/data/LandCoverModel/spark_io/tmp_sparkGlmRunData\", source=\"csv\", mode=\"overwrite\")\n    runMutCollected <- read.df(path = \"/data/LandCoverModel/spark_io/tmp_sparkGlmRunData\", source = \"csv\", schema = schema(runMut))\n    runFit <- glm(TOTRICH~MODAL_CLASS+YR+MODAL_CLASS:YR, family = poisson, data = runMutCollected)\n    runPredData <- distinct(select(runMut, \"MODAL_CLASS\", \"YR\"))\n    predict(runFit, newData = runPredData)\n}","user":"anonymous","dateUpdated":"2017-06-22T14:57:56+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170620-091301_1277937171","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:57:56+0000","dateFinished":"2017-06-22T14:57:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1588"},{"title":"Monte Carlo try-write wrapper functions","text":"%r\ntryWrite <- function(MCFunc, outPath) {\n    wrapped_funct <- function(callValue){\n        errFunct <- function(e) { return(NA) }\n        output <- tryCatch(MCFunc(callValue), error = errFunct, warning = errFunct)\n        if(is.na(output)) {\n            return('failure')\n        }\n        repart <- repartition(output, 1)\n        write.df(repart, path=outPath, source=\"csv\", mode=\"append\")\n        return('success')\n    }\n    return(wrapped_funct)\n}\n\ntryWriteReport <- function(MCList) {\n    report <- unlist(MCList)\n    print(paste0(c(\"Successful runs: \", sum(report == \"success\"), \" / \", length(report)), collapse = \"\"))\n    print(paste0(c(\"Failed runs: \", sum(report == \"failure\"), \" / \", length(report)), collapse = \"\"))\n}","user":"anonymous","dateUpdated":"2017-06-22T14:58:00+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170621-101107_519281725","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:58:00+0000","dateFinished":"2017-06-22T14:58:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1589"},{"title":"Run Spark Monte Carlo stimulation  (write on each loop)","text":"%r\nwriteSparkGlmMC <- tryWrite(sparkGlmMC, \"/data/LandCoverModel/spark_io/sparkGlmResult\")\nsparkMCOutput <- lapply(seq(30), writeSparkGlmMC)\ntryWriteReport(sparkMCOutput)","user":"anonymous","dateUpdated":"2017-06-22T14:58:29+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n[1] “Successful runs: 30 / 30”\n[1] “Failed runs: 0 / 30”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170620-093916_926160492","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T14:58:29+0000","dateFinished":"2017-06-22T15:07:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1590"},{"title":"Define MASS glmmPQL Monte Carlo Function","text":"%r\nmassPqlMC <- function(runIdx) {\n    loadNamespace(\"MASS\")\n    loadNamespace(\"nlme\")\n    runSelect <- select(dtfAll, \"TOTRICH\", \"PIX_DIST\", \"YR\", \"REPEAT_PLO\")\n    runData <- dapply(withColumn(runSelect, \"RAND\", rand()), pixDistSampler, pixDistSampler.schema)\n    runDataMut <- mutate(runData, MODAL_CLASS = cast(runData$MODAL_CLASS, \"string\"), YEAR = cast(runData$YR, \"integer\"))\n    runDataCollect <- collect(runDataMut)\n    runFit <- MASS::glmmPQL((TOTRICH+1)~MODAL_CLASS*YR, random = ~1|REPEAT_PLO, correlation = nlme::corAR1(form=~YEAR|REPEAT_PLO), family = quasipoisson, niter = 100, data = runDataCollect)\n    runPredData <- distinct(select(runDataMut, \"MODAL_CLASS\", \"YR\"))\n    runPredDataCollect <- collect(runPredData)\n    prediction <- predict(runFit, newdata = runPredDataCollect, level = 0, type = \"response\")\n    createDataFrame(cbind(runPredDataCollect, prediction))\n}","user":"anonymous","dateUpdated":"2017-06-22T15:09:17+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170620-134155_1246471953","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T15:09:17+0000","dateFinished":"2017-06-22T15:09:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1591"},{"title":"Run PQL Monte Carlo stimulation (write on each loop)","text":"%r\nwriteMassPqlMC <- tryWrite(massPqlMC, \"/data/LandCoverModel/spark_io/massPqlResult\")\npqlMCOutput <- lapply(seq(6), writeMassPqlMC)\ntryWriteReport(pqlMCOutput)","user":"anonymous","dateUpdated":"2017-06-22T15:14:54+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n[1] “Successful runs: 6 / 6”\n[1] “Failed runs: 0 / 6”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170620-140510_1195197516","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T15:14:54+0000","dateFinished":"2017-06-22T15:27:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1592"},{"text":"%r\n","user":"anonymous","dateUpdated":"2017-06-22T16:04:19+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498147459648_-1344841180","id":"20170622-160419_1652978723","dateCreated":"2017-06-22T16:04:19+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1909"}],"name":"Land Cover Model Monte Carlo Simulation","id":"2CJPPNUAV","angularObjects":{"2CMHTPGFD:shared_process":[],"2CMK8Y3B4:shared_process":[],"2CJXGN79C:shared_process":[],"2CNB6S92Q:shared_process":[],"2CJQ9V7JD:shared_process":[],"2CK6BQQJK:shared_process":[],"2CMPV398Z:shared_process":[],"2CKEACQZW:shared_process":[],"2CN4T7K7Y:shared_process":[],"2CNP9WCDE:shared_process":[],"2CJEMPYH6:shared_process":[],"2CJV16TX1:shared_process":[],"2CNR4MD8Z:shared_process":[],"2CNG9JRFT:shared_process":[],"2CNPEM3N6:shared_process":[],"2CJFPKBM7:shared_process":[],"2CKE1EZS1:shared_process":[],"2CNWAT7NN:shared_process":[],"2CJW8GQZ3:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}