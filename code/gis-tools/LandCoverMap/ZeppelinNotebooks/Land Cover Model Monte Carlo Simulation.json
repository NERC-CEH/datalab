{"paragraphs":[{"title":"Import CSV using Scala","text":"val filePath = \"/data/LandCoverModel/spark_io/LCM_25m_combined/part*\"\nval lcmDataSet = sqlContext.read.format(\"csv\").option(\"inferSchema\", \"true\").load(filePath)\n\nval requiredColumns = lcmDataSet.select(\"_c0\", \"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\", \"_c6\")\nval columnNames = Seq(\"TOTRICH78\", \"TOTRICH90\", \"TOTRICH98\", \"TOTRICH07\", \"PIX_DIST\", \"MODAL_CLASS\", \"REPEAT_PLO\")\nval lcmCleanData = requiredColumns.toDF(columnNames: _*).dropDuplicates(\"REPEAT_PLO\")\n\nrequiredColumns.count()\nlcmCleanData.count() // count after dropping duplicates\n\nlcmCleanData.createOrReplaceTempView(\"cleandata\")\nlcmCleanData.show(5)","user":"anonymous","dateUpdated":"2017-06-22T13:27:47+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494900_1504987402","id":"20170615-135058_169881588","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:46:09+0000","dateFinished":"2017-06-22T08:46:29+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:51015"},{"title":"Collect data in a SparkR Data Frame using SQL","text":"%r\ndtf <- sql(\"select TOTRICH78, TOTRICH90, TOTRICH98, TOTRICH07, PIX_DIST, MODAL_CLASS,  REPEAT_PLO from cleandata\")\nstr(dtf)","user":"anonymous","dateUpdated":"2017-06-22T08:46:31+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494900_1504987402","id":"20170615-120921_1884821392","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:46:31+0000","dateFinished":"2017-06-22T08:46:32+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51016"},{"title":"Reshape data","text":"%r\ncolumnYearLabels <- list(c(\"TOTRICH78\", \"1978\"), c(\"TOTRICH90\", \"1990\"), c(\"TOTRICH98\", \"1998\"), c(\"TOTRICH07\", \"2007\"))\n\nreshapeTR <- function(columnYear) {\n    dtf.filt <- select(dtf, columnYear[1], \"PIX_DIST\", \"MODAL_CLASS\", \"REPEAT_PLO\")\n    dtf.filt$YR <- lit(columnYear[2])\n    dtf.tr <- withColumnRenamed(dtf.filt, columnYear[1], \"TOTRICH\")\n    dtf.tr\n}\n\ndtfAll <- do.call(rbind, lapply(columnYearLabels, reshapeTR))\n\nstr(dtfAll)","user":"anonymous","dateUpdated":"2017-06-22T08:46:36+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494901_1504602653","id":"20170620-104153_1943863007","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:46:36+0000","dateFinished":"2017-06-22T08:46:37+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51017"},{"title":"Spark GLM Introduction","text":"%md\nWhen using R in Zeppelin the library `SparkR` is loaded in the background, this masks some underlying base R functions, most notable the `glm` function is now `SparkR::glm`. This function utilises the `MLlib` Spark library which is very fast for large datasets, but lacks functionality seen with base R glm function. Currently only a few formula operators are supported, including `~`, `.`, `:`, `+`, and `-`. Only `binomial`, `gaussian`, `Gamma`, and `poisson` families will work with `SparkR::glm`. Furthermore, R style factors can not be applied to Spark Data Frames, however, the same effect can be achieve by converting the column to strings.\n\nOur original formula for `stats::glm` was `(TOTRICH+1)~LCM*YR`, this has had to be modified to a two step process.Firstly, we mutate the `TOTRICH` column by adding 1 and convert `LCM` and `YR` to strings - as seen with the `toModel` variable. Secondly, the interaction `A*B` shorthand is not recognised and has to be expanded to be `A+B+A:B`.","user":"anonymous","dateUpdated":"2017-06-22T13:29:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>When using R in Zeppelin the library <code>SparkR</code> is loaded in the background, this masks some underlying base R functions, most notable the <code>glm</code> function is now <code>SparkR::glm</code>. This function utilises the <code>MLlib</code> Spark library which is very fast for large datasets, but lacks functionality seen with base R glm function. Currently only a few formula operators are supported, including <code>~</code>, <code>.</code>, <code>:</code>, <code>+</code>, and <code>-</code>. Only <code>binomial</code>, <code>gaussian</code>, <code>Gamma</code>, and <code>poisson</code> families will work with <code>SparkR::glm</code>. Furthermore, R style factors can not be applied to Spark Data Frames, however, the same effect can be achieve by converting the column to strings.</p>\n<p>Our original formula for <code>stats::glm</code> was <code>(TOTRICH+1)~LCM*YR</code>, this has had to be modified to a two step process.Firstly, we mutate the <code>TOTRICH</code> column by adding 1 and convert <code>LCM</code> and <code>YR</code> to strings - as seen with the <code>toModel</code> variable. Secondly, the interaction <code>A*B</code> shorthand is not recognised and has to be expanded to be <code>A+B+A:B</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1498059494901_1504602653","id":"20170616-152529_553294767","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T13:29:53+0000","dateFinished":"2017-06-22T13:29:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:51018"},{"title":"Model \"Modal Class\" using SparkR GLM","text":"%r\n# SparkR GLM can not mutate values before modelling\ntoModel <- mutate(dtfAll, TOTRICH=cast(dtfAll$TOTRICH + 1, \"integer\"), MODAL_CLASS=cast(dtfAll$MODAL_CLASS, \"string\"))\nstr(toModel)\n\nsparkFit <- glm(TOTRICH~MODAL_CLASS+YR+MODAL_CLASS:YR, family=poisson, data=toModel)","user":"anonymous","dateUpdated":"2017-06-22T08:43:30+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494901_1504602653","id":"20170615-135849_1422525712","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:43:30+0000","dateFinished":"2017-06-22T08:43:52+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51019"},{"title":"Create prediction data-set from Spark Data Frame","text":"%r\n# Created SparkR Data Frame is unordered\ntoFitNewValues <- arrange(distinct(select(toModel, \"MODAL_CLASS\", \"YR\")), \"YR\", \"MODAL_CLASS\")\nstr(toFitNewValues)","user":"anonymous","dateUpdated":"2017-06-22T08:43:57+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170619-081700_893612832","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:43:57+0000","dateFinished":"2017-06-22T08:44:00+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51020"},{"title":"Generate predictions from Spark GLM model","text":"%r\n# Spark::Predict missing level and type arguments \nsparkPredict <- predict(sparkFit, newData = toFitNewValues)\nhead(sparkPredict)","user":"anonymous","dateUpdated":"2017-06-22T08:44:02+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170616-135554_478749562","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:44:02+0000","dateFinished":"2017-06-22T08:44:04+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51021"},{"title":"Define the pixel distribution sampler function","text":"%r\npixDistSampler <- function(sparkDF) {\n    # sparkDataFrame is a fragment of the entire data frame.\n    nrows <- nrow(sparkDF)\n    for(i in 1:nrows){\n        row <- sparkDF[i,]\n        pixDist.counts <- as.double(unlist(strsplit(row$PIX_DIST, \",\")))\n        pixDist.randCount <- sum(pixDist.counts) * row$RAND\n        pixDist.csum <- cumsum(pixDist.counts)\n        pixDist.idx <- which(pixDist.csum >= pixDist.randCount)\n        sparkDF[i,6] <-  as.integer(pixDist.idx[1])\n    }\n    sparkDF\n}\n\npixDistSampler.schema <- structType(structField(\"TOTRICH\", \"integer\"), structField(\"PIX_DIST\", \"string\"),  structField(\"YR\", \"string\"), structField(\"REPEAT_PLO\", \"string\"),\n     structField(\"RAND\", \"double\"), structField(\"MODAL_CLASS\", \"integer\"))","user":"anonymous","dateUpdated":"2017-06-22T08:46:55+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170619-164436_953728566","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:46:55+0000","dateFinished":"2017-06-22T08:46:55+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51022"},{"title":"Define Spark GLM Monte Carlo function","text":"%r\nsparkGlmMC <- function(runIdx) {\n    runSelect <- select(dtfAll, \"TOTRICH\", \"PIX_DIST\", \"YR\", \"REPEAT_PLO\")\n    runData <- dapply(withColumn(runSelect, \"RAND\", rand()), pixDistSampler, pixDistSampler.schema)\n    runMut <- mutate(runData, TOTRICH = runData$TOTRICH + 1, MODAL_CLASS = cast(runData$MODAL_CLASS, \"string\"))\n    # Spark GLM issue causes Spark Context to intermittently crash, write and reload data from disk\n    write.df(runMut, path=\"/data/LandCoverModel/spark_io/tmp_sparkGlmRunData\", source=\"csv\", mode=\"overwrite\")\n    # Reload data from disk\n    runMutCollected <- read.df(path = \"/data/LandCoverModel/spark_io/tmp_sparkGlmRunData\", source = \"csv\", schema = schema(runMut))\n    runFit <- glm(TOTRICH~MODAL_CLASS+YR+MODAL_CLASS:YR, family = poisson, data = runMutCollected)\n    runPredData <- distinct(select(runMut, \"MODAL_CLASS\", \"YR\"))\n    predict(runFit, newData = runPredData)\n}","user":"anonymous","dateUpdated":"2017-06-22T13:27:47+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494902_1505756900","id":"20170620-091301_1277937171","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:46:57+0000","dateFinished":"2017-06-22T08:46:57+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51023"},{"title":"Monte Carlo try-write wrapper function","text":"%r\ntryWrite <- function(MCFunc, outPath) {\n    wrapped_funct <- function(callValue){\n        errFunct <- function(e) { return(NA) }\n        output <- tryCatch(MCFunc(callValue), error = errFunct, warning = errFunct)\n        if(is.na(output)) {\n            return('failure')\n        }\n        repart <- repartition(output, 1)\n        write.df(repart, path=outPath, source=\"csv\", mode=\"append\")\n        return('success')\n    }\n    return(wrapped_funct)\n}\n\ntryWriteReport <- function(MCList) {\n    report <- unlist(MCList)\n    print(paste0(c(\"Successful runs: \", sum(report == \"success\"), \" / \", length(report)), collapse = \"\"))\n    print(paste0(c(\"Failed runs: \", sum(report == \"failure\"), \" / \", length(report)), collapse = \"\"))\n}","user":"anonymous","dateUpdated":"2017-06-22T08:46:58+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170621-101107_519281725","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:46:58+0000","dateFinished":"2017-06-22T08:46:58+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51024"},{"title":"Run Spark Monte Carlo stimulation  (write on each loop)","text":"%r\nwriteSparkGlmMC <- tryWrite(sparkGlmMC, \"/data/LandCoverModel/spark_io/sparkGlmResult\")\nsparkMCOutput <- lapply(seq(2), writeSparkGlmMC)\ntryWriteReport(sparkMCOutput)","user":"anonymous","dateUpdated":"2017-06-22T13:27:47+0000","config":{"editorSetting":{"language":"r"},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170620-093916_926160492","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:44:25+0000","dateFinished":"2017-06-22T08:45:08+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51025"},{"title":"Define MASS glmmPQL Monte Carlo Function","text":"%r\nmassPqlMC <- function(runIdx) {\n    loadNamespace(\"MASS\")\n    loadNamespace(\"nlme\")\n    runSelect <- select(dtfAll, \"TOTRICH\", \"PIX_DIST\", \"YR\", \"REPEAT_PLO\")\n    runData <- dapply(withColumn(runSelect, \"RAND\", rand()), pixDistSampler, pixDistSampler.schema)\n    runDataMut <- mutate(runData, MODAL_CLASS = cast(runData$MODAL_CLASS, \"string\"), YEAR = cast(runData$YR, \"integer\"))\n    runDataCollect <- collect(runDataMut)\n    runFit <- MASS::glmmPQL((TOTRICH+1)~MODAL_CLASS*YR, random = ~1|REPEAT_PLO, correlation = nlme::corAR1(form=~YEAR|REPEAT_PLO), family = quasipoisson, niter = 100, data = runDataCollect)\n    runPredData <- distinct(select(runDataMut, \"MODAL_CLASS\", \"YR\"))\n    runPredDataCollect <- collect(runPredData)\n    prediction <- predict(runFit, newdata = runPredDataCollect, level = 0, type = \"response\")\n    createDataFrame(cbind(runPredDataCollect, prediction))\n}","user":"anonymous","dateUpdated":"2017-06-22T08:47:05+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170620-134155_1246471953","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:47:05+0000","dateFinished":"2017-06-22T08:47:05+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51026"},{"title":"Run PQL Monte Carlo stimulation (write on each loop)","text":"%r\nwriteMassPqlMC <- tryWrite(massPqlMC, \"/data/LandCoverModel/spark_io/massPqlResult\")\npqlMCOutput <- lapply(seq(2), writeMassPqlMC)\ntryWriteReport(pqlMCOutput)","user":"anonymous","dateUpdated":"2017-06-22T13:27:47+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494903_1505372151","id":"20170620-140510_1195197516","dateCreated":"2017-06-21T15:38:14+0000","dateStarted":"2017-06-22T08:47:09+0000","dateFinished":"2017-06-22T08:51:15+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51027"},{"text":"%r\n","dateUpdated":"2017-06-21T15:38:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/r","results":{},"enabled":true,"editorSetting":{"language":"r"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1498059494904_1503448406","id":"20170621-150112_1512378567","dateCreated":"2017-06-21T15:38:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:51028"}],"name":"Land Cover Model Monte Carlo Simulation","id":"2CJPPNUAV","angularObjects":{"2CJCG9YGH:shared_process":[],"2CMMNW7MR:shared_process":[],"2CKEQTZDW:shared_process":[],"2CNKKUJDJ:shared_process":[],"2CK113UY1:shared_process":[],"2CMCUVPQV:shared_process":[],"2CKUQT3KT:shared_process":[],"2CMT2DHBM:shared_process":[],"2CN4BZX5B:shared_process":[],"2CKBH6PKV:shared_process":[],"2CNH6WYSG:shared_process":[],"2CJZHZPXJ:shared_process":[],"2CMUXRQW7:shared_process":[],"2CJDPRR2G:shared_process":[],"2CK3RHEJU:shared_process":[],"2CK68AC9T:shared_process":[],"2CNQJ1MP7:shared_process":[],"2CKEKKSZA:shared_process":[],"2CKV2TXGB:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}